import json
from elasticsearch import Elasticsearch, helpers
from concurrent.futures import ThreadPoolExecutor, as_completed

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
ES_HOST = "http://localhost:9200"
ES_INDEX = "vacancies"
BATCH_SIZE = 1000  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
MAX_WORKERS = 4    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
es = Elasticsearch(ES_HOST)

def recreate_index():
    if es.indices.exists(index=ES_INDEX):
        print(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å '{ES_INDEX}'...")
        es.indices.delete(index=ES_INDEX)
    
    print(f"‚ú® –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å '{ES_INDEX}' –±–µ–∑ —è–≤–Ω–æ–≥–æ –º–∞–ø–ø–∏–Ω–≥–∞...")
    es.indices.create(index=ES_INDEX)
    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å '{ES_INDEX}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")

def send_batch(batch, batch_number):
    helpers.bulk(es, batch)
    print(f"üì§ –ü–∞–∫–µ—Ç ‚Ññ{batch_number} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω ({len(batch)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)")

def load_data_to_elasticsearch_parallel(jsonl_file_path):
    batch = []
    futures = []
    batch_number = 1

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        with open(jsonl_file_path, "r", encoding="utf-8") as file:
            for i, line in enumerate(file, start=1):
                doc = json.loads(line)
                action = {
                    "_index": ES_INDEX,
                    "_id": doc.get("id"),
                    "_source": doc
                }
                batch.append(action)

                if len(batch) >= BATCH_SIZE:
                    future = executor.submit(send_batch, batch.copy(), batch_number)
                    futures.append(future)
                    batch = []
                    batch_number += 1

            # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            if batch:
                future = executor.submit(send_batch, batch.copy(), batch_number)
                futures.append(future)

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
        for future in as_completed(futures):
            future.result()

    print(f"‚úÖ –í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ Elasticsearch –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.")

if __name__ == "__main__":
    recreate_index()
    load_data_to_elasticsearch_parallel("full_vacancies_stream.jsonl")
